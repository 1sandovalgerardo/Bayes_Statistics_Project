---
title: "Final Project"
output: html_notebook
Authors: Danielle Buhr and Gerardo Sandoval
---

 
```{r}

library(ggplot2) # for graphs
library(rjags)
library(dplyr)
#library(fBasics)
#library(forecast)

```


## Load Data
```{r}
spy_path = paste(getwd(), '/SPY.csv', sep='')

spy_data = read.csv(spy_path)
head(spy_data)
#View(spy_data)#

```


## Variables
```{r}
#### Create Change Variables ####
spy_data = spy_data %>%
  dplyr::mutate(change1 = (Adj.Close - lag(Adj.Close, n=1))/ lag(Adj.Close, n=1),
                change3 = (Adj.Close - lag(Adj.Close, n=3))/ lag(Adj.Close, n=3),
                change5 = (Adj.Close - lag(Adj.Close, n=5))/ lag(Adj.Close, n=5),
                change10 = (Adj.Close - lag(Adj.Close, n=10))/ lag(Adj.Close, n=10),
                change0 = (Close - Open) / Open
                )
hist(spy_data$change3, breaks=50)

```



*G.S.*: I was thinking of analyzing the absolute values to make the logistic regression work a bit easier

```{r}
abs_data = spy_data %>%
  dplyr::mutate(change1 = abs((Adj.Close - lag(Adj.Close, n=1))/ lag(Adj.Close, n=1)),
                change3 = abs((Adj.Close - lag(Adj.Close, n=3))/ lag(Adj.Close, n=3)),
                change5 = abs((Adj.Close - lag(Adj.Close, n=5))/ lag(Adj.Close, n=5)),
                change10 = abs((Adj.Close - lag(Adj.Close, n=10))/ lag(Adj.Close, n=10))
                )


hist(abs_data$change3, breaks=50)

mean(na.omit(abs_data$change3))

```


#### Volume Variables
```{r}
# Function to normalize volume
norm_volume = function(data, new_max, new_min){
  return(data-min(data)) / (max(data)-min(data)) * (new_max-new_min) + new_min
}

### Normalized Volume ###
spy_data$Norm_Volume = norm_volume(spy_data$Volume, 3, 1)


```

### Advance Decline Variables
```{r}

# mutate is from dplyr
spy_data = spy_data %>%
  mutate(Volume_Dir = (change0/abs(change0))*Norm_Volume,
         Adv_Dec = cumsum(ifelse(is.na(Volume_Dir), 0, Volume_Dir)),
         AD_Change1 = (Adv_Dec - lag(Adv_Dec)) / lag(Adv_Dec),
         AD_Change3 = (Adv_Dec - lag(Adv_Dec,n=3)) / lag(Adv_Dec,n=3),
         AD_Change5 = (Adv_Dec - lag(Adv_Dec,n=5)) / lag(Adv_Dec,n=5)
         )
plot(spy_data$Adv_Dec, type='l', xlim=c(1000,5000))
plot(spy_data$AD_Change1, type='l', xlim=c(1000,5000), ylim=c(-1,1))

sd(spy_data$change1)
sd(spy_data$change3)
```


#### Response Variable
*G.S.*: We want to predict what the change will be from today over the next 5 days. So I shifted the change5 column to create a response column
```{r}

spy_data$Response = lead(spy_data$change5, n=5)

check_values = subset(spy_data, select = c(Response, change5))
head(check_values, n=10)

```


## JAG Structure

```{r}
spy_data = na.omit(spy_data)
Y = spy_data$Response
X = subset(spy_data, select=c(Norm_Volume, change1, change3, Adv_Dec))
X1 = spy_data$Norm_Volume
X2 = spy_data$change1
X3 = spy_data$change3
X4 = spy_data$Adv_Dec

n = length(Y)
p = ncol(X)
data = list(Y=Y, X1=X1, X2=X2, X3=X3, X4=X4, n=n)#, p=p)
params = c('alpha', 'beta1', 'beta2', 'beta3', 'beta4') 
names = c('alpha',"Norm_Volume", "change1", 'change3', 'Adv_Dec')

nBurn = 10000
nChains = 2
nSave = 4000
nThin = 5
nIter = ceiling((nSave*nThin)/nChains)

```


##1. Fit the uninformative Gaussian model 
$\beta_{j} \sim \text{Normal}(0,1000)$


## NOT: I have changed Tau 1 to Taue for all three models
```{r}
model_string1 = textConnection("
  model{
  # Likelihood
  for(i in 1:n){
    Y[i] ~ dnorm(alpha + X1[i]*beta1+ X2[i]*beta2+ X3[i]*beta3+ X4[i]*beta4, taue)
  }
  # Priors
  beta1 ~ dnorm(0, 0.001)
  beta2 ~ dnorm(0, 1/0.012)
  beta3 ~ dnorm(0, 1/0.019)
  beta4 ~ dnorm(0, 0.001)
  taue ~ dgamma(0.1, 0.1) 
  alpha ~ dnorm(0, 0.001)
  }")

model1 = jags.model(model_string1, data=data, n.chains=nChains, quiet=T)
update(model1, burn=nBurn, progress.bar='text')
samples1 = coda.samples(model1, variable.names=params, thin=nThin, n.iter=nIter, progress.bar='text')


```


### RESULTS (1.)
```{r}
plot(samples1)
round(effectiveSize(samples1), 1)
sum1 = summary(samples1)
rownames(sum1$statistics) = names
rownames(sum1$quantiles) = names
sum1

```


##2. Fit the Gaussian shrinkage model   
$\beta_{j} \sim \text{Normal}(0,\sigma_{b}^{2} )$ with $\sigma_{b}^{2} \sim \text{InvGamma}(0.1,0.1)$ 
```{r}
model_string2 = textConnection("
  model{
  # Likelihood
  for(i in 1:n){
    Y[i] ~ dnorm(alpha + X1[i]*beta1+ X2[i]*beta2+ X3[i]*beta3+ X4[i]*beta4, taue)
  }
  # Priors
  beta1 ~ dnorm(0, taub*taue)  #shrinkage
  beta2 ~ dnorm(0, taub*taue)
  beta3 ~ dnorm(0, taub*taue)
  beta4 ~ dnorm(0, taub*taue)
  taue ~ dgamma(0.1, 0.1) 
  taub  ~ dgamma(0.1, 0.1)
  alpha ~ dnorm(0, 0.001)
  }")
model2 = jags.model(model_string2, data=data, n.chains=nChains, quiet=T)
update(model2, burn=nBurn, progress.bar='text')
samples2 = coda.samples(model2, variable.names=params, thin=nThin, n.iter=nIter, progress.bar='text')
```

### RESULTS (2.)

```{r}
plot(samples2)
round(effectiveSize(samples2), 1)
sum2 = summary(samples2)
rownames(sum2$statistics) = names 
rownames(sum2$quantiles) = names
sum2

```

##3. Fit the Bayesian LASSO  
$\beta_{j} \sim \text{DE}(0,\sigma_{b}^{2} )$ with $\sigma_{b}^{2} \sim \text{InvGamma}(0.1,0.1)$ 
DE = double exponential
NOTE: You can change progress.bar='none'
That avoids printing the pesky status bar.
The output is different when run in through a command line.
```{r}
model_string <- textConnection("model{
  # Likelihood
  for(i in 1:n){
    Y[i] ~ dnorm(alpha + X1[i]*beta1+ X2[i]*beta2+ X3[i]*beta3+ X4[i]*beta4, taue)
  }
  # Priors
  beta1 ~ ddexp(0,taub*taue)  #shrinkage
  beta2 ~ ddexp(0,taub*taue)
  beta3 ~ ddexp(0,taub*taue)
  beta4 ~ ddexp(0,taub*taue)
  taue ~ dgamma(0.1, 0.1) 
  alpha ~ dnorm(0, 0.001)
  taub  ~ dgamma(0.1, 0.1)
}")

model <- jags.model(model_string,data=data,n.chains=nChains,quiet=TRUE)
update(model,burn=nBurn,progress.bar="none")
samples3 <- coda.samples(model,variable.names=params,thin=nThin,n.iter=nIter,
                         progress.bar="none")

```

### RESULTS (2.)

```{r}
plot(samples3)
round(effectiveSize(samples3), 1)
sum3 = summary(samples3)
rownames(sum3$statistics) = names 
rownames(sum3$quantiles) = names
sum3

```

### Compare three fits  
	1. Uninformative Gaussian  
	2. Gaussian shrinkage  
	3. Bayesian Lasso  
	
	
*You will have to  change this to make it work with your variable syntax*
```{r}

library(cowplot)
plot_list <- list()

for(j in 1:p){
  
  # Collect the MCMC iteration from both chains for the three priors <--------- this will likely not work with your syntax
  s1 <- c(samples1[[1]][,j],samples1[[2]][,j])
  s2 <- c(samples2[[1]][,j],samples2[[2]][,j])
  s3 <- c(samples3[[1]][,j],samples3[[2]][,j])
  
  # Get smooth density estimates for each prior
  d1 <- density(s1)
  d2 <- density(s2)
  d3 <- density(s3)
  
  Prior <- c(rep("Uninformative Gaussian",length(d1$x)),
             rep("Gaussian shrinkage",length(d2$x)),
             rep("Bayesian LASSO",length(d3$x)))
  x <- c(d1$x,d2$x,d3$x)
  y <- c(d1$y,d2$y,d3$y)
  d.data <- data.frame(x=x,y=y,Prior=Prior)
  
  # Plot the density estimates
  max.y <- max(y)
  plot.title <- names[j]
  g <- ggplot(d.data,aes(x=x,y=y,color=Prior))+geom_line()+
    labs(x=expression(beta),y="Posterior density")+ggtitle(plot.title)+
    ylim(c(0,max.y))+geom_vline(xintercept=0)
  plot_list[[j]] <- g+theme(legend.position="none")
}
prow <- plot_grid(plotlist=plot_list,nrow=4)
legend <- get_legend(g+guides(color=guide_legend(reverse=TRUE,nrow=1))+
                       theme(legend.position="bottom"))
plot_grid(prow,legend,nrow=5,rel_heights = c(1,0.1))

```


## Diagnostics    

#### Graphical
```{r}
autocorr.plot(samples1)
autocorr.plot(samples2)
autocorr.plot(samples3)


```


#### Numerical  

###Convergence  

 Low autocorrelation indicates convergence  
 Autocorrelation near 1 indicates poor convergence  
 samples[[1]] means you are looking at the 1st chain  
```{r}
autocorr(samples[[1]],lag=1)
```



Low ESS indicates poor convergence  
ESS over 1000 indicates convergence  

```{r}

effectiveSize(samples)
```


R less than 1.1 indicates convergence  

```{r}

gelman.diag(samples)
```
 
|z| less than 2 indicates convergence  
```{r}
geweke.diag(samples[[1]])
```


## Model comparison  
Do we want to add another model? like compare our curent model with a model for interaction?
```{r}
#see week9
```

## Prediction?

After we pick a model and complete diagnostics, do we try Posterior predictive distribution (PPD)? the distribution of the predicted value marginally over model parameters?
 
 

